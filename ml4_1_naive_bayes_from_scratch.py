# -*- coding: utf-8 -*-
"""ML4_1 -- Naive Bayes from scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MhCqhb_Oe_fvBqAL-gOFE0EI4EzR2o5L
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import math

data=pd.read_csv('/content/drive/MyDrive/SEM 4/breastcancer.csv')
data.head()

data.shape

data.info()

data.describe()

data.isna().sum()

fig = plt.figure(figsize=(30,20))
sns.heatmap(data.corr(),annot=True)

df=pd.DataFrame(data)
df.head()

Y=df['diagnosis']
Y.head()

print(Y.unique())
print(Y.nunique())

X=df.drop(['id','diagnosis'],axis=1)
X.head()

#correlation matrix
corr_matrix = X.corr().abs()

# Select upper triangle of correlation matrix
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

# Find features with correlation greater than 0.5
to_drop = [column for column in upper.columns if any(upper[column] > 0.5)]

# Drop fetures
X.drop(to_drop, axis=1, inplace=True)

X.info()

X.hist(figsize=(10,10))
plt.show()

X.drop(['texture_se','smoothness_se','symmetry_se','Unnamed: 32'],axis=1,inplace=True)

X.info()

df2 =X
df2['diagnosis'] =Y
df2['diagnosis'] = df['diagnosis'].map({'M':0 ,'B':1})
df2

fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)
sns.histplot(df2, ax=axes[0], x="radius_mean", kde=True, color='g')
sns.histplot(df2, ax=axes[1], x="texture_mean", kde=True, color='r')
sns.histplot(df2, ax=axes[2], x="smoothness_mean", kde=True, color='b')

"""Calculate P(Y=y) for all possible y"""

def calculate_prior(df, Y):
  classes = sorted(list(df[Y].unique()))
  prior = []
  for i in classes:
      prior.append(len(df[df[Y]==i])/len(df))
  return prior

"""Calculate P(X=x|Y=y) using Gaussian dist"""

def calculate_likelihood_gaussian(df, feat_name, feat_val, Y, label):
  feat = list(df.columns)
  df = df[df[Y]==label]
  mean, std = df[feat_name].mean(), df[feat_name].std()
  p_x_given_y = (1 / (np.sqrt(2 * np.pi) * std)) *  np.exp(-((feat_val-mean)**2 / (2 * std**2 )))
  return p_x_given_y

"""Calculate P(X=x1|Y=y)P(X=x2|Y=y)...P(X=xn|Y=y) * P(Y=y) for all y and find the maximum"""

def naive_bayes_gaussian(df, X, Y):
  # get feature names
  features = list(df.columns)[:-1]

  # calculate prior
  prior = calculate_prior(df, Y)

  Y_pred = []
  # loop over every data sample
  for x in X:
      # calculate likelihood
      labels = sorted(list(df[Y].unique()))
      likelihood = [1]*len(labels)
      for j in range(len(labels)):
          for i in range(len(features)):
              likelihood[j] *= calculate_likelihood_gaussian(df, features[i], x[i], Y, labels[j])

      # calculate posterior probability (numerator only)
      post_prob = [1]*len(labels)
      for j in range(len(labels)):
          post_prob[j] = likelihood[j] * prior[j]

      Y_pred.append(np.argmax(post_prob))

  return np.array(Y_pred) def get_models():
    models = []
    for lr in [0.1, 0.5, 0.01, 0.05, 0.2, 0.02, 0.3, 0.03, 0.4, 0.04, 0.06]:
        dtc = DecisionTreeClassifier(max_depth=2, random_state=42)
        ada = AdaBoostClassifier(estimator=dtc, learning_rate=lr, random_state=42)
        models.append(ada)
    return models

def evaluate_model(model, X, y):
    kfold = KFold(n_splits=10, shuffle=True, random_state=101)
    scores = cross_val_score(model, X, y, cv=kfold)
    print(f"Learning rate: {model.learning_rate:.2f}, Accuracy: {scores.mean():.3f}")

models = get_models()
for model in models:
    evaluate_model(model, X, y)

"""Test Gaussian model"""

from sklearn.model_selection import train_test_split
train, test = train_test_split(df2, test_size=.2, random_state=41)

X_test = test.iloc[:,:-1].values
Y_test = test.iloc[:,-1].values
Y_pred = naive_bayes_gaussian(train, X=X_test, Y="diagnosis")

from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report

print(f"Testing Accuracy = {accuracy_score(Y_test,Y_pred)}")

cm=confusion_matrix(Y_test,Y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)
plt.show()

print(classification_report(Y_test,Y_pred))